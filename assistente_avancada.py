# assistente_avancada.py - PARCEIRO DE F√â AVAN√áADO (FINAL)

import os
import json
import logging
from google import genai
from google.genai import types
from google.genai.errors import APIError

logger = logging.getLogger(__name__)

# O texto inicial que define o comportamento do assistente
INSTRUCAO_SISTEMA_PADRAO = """
Voc√™ √© Esperan√ßa, uma parceira de f√© virtual, desenvolvida para auxiliar a Igreja Esperan√ßa Pontal Sul.
Seu objetivo principal √© oferecer informa√ß√µes sobre a igreja, seus hor√°rios, localiza√ß√£o, 
princ√≠pios e contatos, com uma abordagem acolhedora, crist√£ e inspirada na B√≠blia.

Sua personalidade √©:
1. Acolhedora e Pastoral: Mantenha um tom de f√©, esperan√ßa e amor.
2. Informativa: Baseie-se nas informa√ß√µes de CONHECIMENTO_ATUAL.
3. Objetiva: Responda diretamente ao que foi perguntado.
4. Use emojis crist√£os e de paz (ex: üïäÔ∏è, üôè, üíñ).

INSTRU√á√ïES ESPEC√çFICAS:
- Nunca gere imagens.
- N√£o crie ou sugira rituais ou dogmas que n√£o estejam explicitamente no CONHECIMENTO_ATUAL.
- Mantenha respostas curtas e diretas. Se a resposta for longa, use par√°grafos.
- Sempre que a resposta for um link de contato ou localiza√ß√£o (WhatsApp, Mapa, Hor√°rios),
  sugira o link usando um 'chip' de link clic√°vel no formato HTML:
  <a href="{URL}" target="_blank" class="chip link-chip">{TEXTO}</a>
  
### CONHECIMENTO_ATUAL ###
{CONHECIMENTO_TEXTO}

### LINKS_DE_CONTATO ###
{LINKS_DE_CONTATO}

"""

class ParceiroDeFeAvancado:
    def __init__(self, contatos, conhecimento_texto=None):
        self.api_key = os.getenv('GEMINI_API_KEY')
        if not self.api_key:
            raise ValueError("A vari√°vel de ambiente GEMINI_API_KEY n√£o est√° configurada.")

        self.client = genai.Client(api_key=self.api_key)
        self.model = 'gemini-2.5-flash'  # Modelo r√°pido para chat
        
        # Dados de contexto
        self.contatos = contatos
        self.conhecimento_texto = conhecimento_texto if conhecimento_texto is not None else self._carregar_conhecimento_padrao()
        
        # Atualiza a instru√ß√£o do sistema com o conhecimento carregado
        self._atualizar_instrucao_sistema()

    def _carregar_conhecimento_padrao(self):
        """Carrega o conhecimento do arquivo padr√£o."""
        try:
            with open('conhecimento_esperancapontalsul.txt', 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            logger.warning("Arquivo 'conhecimento_esperancapontalsul.txt' n√£o encontrado. Usando conhecimento vazio.")
            return "Nenhum conhecimento base dispon√≠vel."
            
    def _atualizar_instrucao_sistema(self):
        """Gera a instru√ß√£o completa do sistema com contexto."""
        links_json = json.dumps(self.contatos, indent=2, ensure_ascii=False)
        self.instrucao_sistema = INSTRUCAO_SISTEMA_PADRAO.format(
            CONHECIMENTO_TEXTO=self.conhecimento_texto,
            LINKS_DE_CONTATO=links_json
        )

    def iniciar_novo_chat(self):
        """Inicia um novo hist√≥rico de chat."""
        # Retorna o formato serializ√°vel (lista de dicion√°rios)
        return []

    def enviar_saudacao(self):
        """Gera a sauda√ß√£o inicial usando o modelo."""
        prompt = "Gere uma breve e calorosa mensagem de sauda√ß√£o inicial para um visitante do chat."
        
        # Cria uma sess√£o tempor√°ria de chat apenas para a sauda√ß√£o
        chat = self.client.chats.create(
            model=self.model,
            system_instruction=self.instrucao_sistema
        )
        
        try:
            response = chat.send_message(prompt)
            return response.text
        except APIError as e:
            logger.error(f"Erro na API ao gerar sauda√ß√£o: {e}")
            return "Ol√°! Sou Esperan√ßa, sua parceira de f√© virtual. Tivemos um pequeno erro t√©cnico, mas estou aqui para te ajudar. Como posso servir?"
        except Exception as e:
            logger.error(f"Erro inesperado ao gerar sauda√ß√£o: {e}")
            return "Ol√°! Sou Esperan√ßa, sua parceira de f√© virtual. O servidor de IA falhou ao iniciar, mas estou aqui para te ajudar. Como posso servir?"


    def obter_resposta_com_memoria(self, historico_serializado, pergunta):
        """
        Recebe o hist√≥rico serializado (lista de dicts), reconstr√≥i o objeto Content, 
        envia a pergunta e retorna a resposta e o novo hist√≥rico serializ√°vel.
        """
        
        # 1. Reconstruir o hist√≥rico de Content a partir do JSON serializado
        historico_gemini = []
        for item in historico_serializado:
            try:
                # CORRE√á√ÉO CR√çTICA: Tenta reconstruir o objeto Content passando o dicion√°rio.
                # A classe types.Content (ou types.Content) suporta o construtor direto
                historico_gemini.append(types.Content(**item))
            except Exception as e:
                # Se falhar (como o erro from_dict), retorna o erro para debug
                logger.error(f"Falha ao reconstruir item do hist√≥rico: {item}. Erro: {e}")
                raise e # Propaga o erro para que o log do render o pegue.

        # 2. Iniciar ou continuar o chat com o hist√≥rico reconstru√≠do
        chat = self.client.chats.create(
            model=self.model,
            system_instruction=self.instrucao_sistema,
            history=historico_gemini
        )
        
        # 3. Enviar a nova mensagem
        response = chat.send_message(pergunta)
        
        # 4. Preparar o hist√≥rico para a sess√£o (Serializa√ß√£o)
        # O objeto de hist√≥rico do chat.get_history() cont√©m os Content gerados pelo modelo.
        novo_historico_gemini = chat.get_history()
        
        return response.text, novo_historico_gemini